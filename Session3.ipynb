{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access your API key\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=\"Calculate the sum of exponentials of first 3 Fibonacci numbers\",\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first 3 Fibonacci numbers are $F_1=1$, $F_2=1$, and $F_3=2$.\n",
    "We want to calculate the sum of exponentials of these first 3 Fibonacci numbers.\n",
    "Let the sum be $S = e^{F_1} + e^{F_2} + e^{F_3}$.\n",
    "We have $F_1=1$, $F_2=1$, and $F_3=2$.\n",
    "Then $S = e^1 + e^1 + e^2 = e + e + e^2 = 2e + e^2$.\n",
    "We can approximate the value of $e$ as $2.71828$.\n",
    "So, $S = 2e + e^2 \\approx 2(2.71828) + (2.71828)^2 \\approx 5.43656 + 7.3890561984 \\approx 12.8256161984$.\n",
    "\n",
    "We are asked to calculate the sum of exponentials of the first 3 Fibonacci numbers.\n",
    "Let the first 3 Fibonacci numbers be $F_1$, $F_2$, and $F_3$.\n",
    "Then $F_1 = 1$, $F_2 = 1$, $F_3 = 2$.\n",
    "The sum of exponentials of these numbers is $e^{F_1} + e^{F_2} + e^{F_3} = e^1 + e^1 + e^2 = e + e + e^2 = 2e + e^2 = e(2+e)$.\n",
    "If we use the approximation $e \\approx 2.71828$, then\n",
    "$2e + e^2 \\approx 2(2.71828) + (2.71828)^2 \\approx 5.43656 + 7.3890561984 \\approx 12.8256161984$.\n",
    "\n",
    "The exact value is $2e + e^2$.\n",
    "\n",
    "Final Answer: The final answer is $\\boxed{2e+e^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model's response\n",
    "system_prompt = \"\"\"You are a math agent. Respond with EXACTLY ONE of these formats:\n",
    "1. FUNCTION_CALL: python_function_name|input\n",
    "2. FINAL_ANSWER: [number]\n",
    "\n",
    "where python_function_name is one of the followin:\n",
    "1. strings_to_chars_to_int(string) It takes a word as input, and returns the ASCII INT values of characters in the word as a list\n",
    "2. int_list_to_exponential_sum(list) It takes a list of integers and returns the sum of exponentials of those integers\n",
    "3. fibonacci_numbers(int) It takes an integer, like 6, and returns first 6 integers in a fibonacci series as a list.\n",
    "DO NOT include multiple responses. Give ONE response at a time.\"\"\"\n",
    "\n",
    "current_query= \"\"\"Calculate the sum of exponentials of word \"TSAI\"\"\"\n",
    "\n",
    "prompt = f\"{system_prompt}\\n\\nQuery: {current_query}\"\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=prompt\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def strings_to_chars_to_int(string):\n",
    "    return [ord(char) for char in string]\n",
    "\n",
    "def int_list_to_exponential_sum(int_list):\n",
    "    int_list = eval(int_list)\n",
    "    return sum(math.exp(i) for i in int_list)\n",
    "\n",
    "def fibonacci_numbers(n):\n",
    "    if n <= 0:\n",
    "        return []\n",
    "    fib_sequence = [0, 1]\n",
    "    for _ in range(2, n):\n",
    "        fib_sequence.append(fib_sequence[-1] + fib_sequence[-2])\n",
    "    return fib_sequence[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_text = response.text.strip()\n",
    "response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, function_info = response_text.split(\":\", 1)\n",
    "_, function_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_name, params = [x.strip() for x in function_info.split(\"|\", 1)]\n",
    "\n",
    "func_name, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_caller(func_name, params):\n",
    "    \"\"\"Simple function caller that maps function names to actual functions\"\"\"\n",
    "    function_map = {\n",
    "        \"strings_to_chars_to_int\": strings_to_chars_to_int,\n",
    "        \"int_list_to_exponential_sum\": int_list_to_exponential_sum,\n",
    "        \"fibonacci_numbers\": fibonacci_numbers\n",
    "    }\n",
    "    \n",
    "    if func_name in function_map:\n",
    "        return function_map[func_name](params)\n",
    "    else:\n",
    "        return f\"Function {func_name} not found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration_result = function_caller(func_name, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model's response\n",
    "system_prompt = \"\"\"You are a math agent solving problems in iterations. Respond with EXACTLY ONE of these formats:\n",
    "1. FUNCTION_CALL: python_function_name|input\n",
    "2. FINAL_ANSWER: [number]\n",
    "\n",
    "where python_function_name is one of the followin:\n",
    "1. strings_to_chars_to_int(string) It takes a word as input, and returns the ASCII INT values of characters in the word as a list\n",
    "2. int_list_to_exponential_sum(list) It takes a list of integers and returns the sum of exponentials of those integers\n",
    "3. fibonacci_numbers(int) It takes an integer, like 6, and returns first 6 integers in a fibonacci series as a list.\n",
    "DO NOT include multiple responses. Give ONE response at a time.\"\"\"\n",
    "\n",
    "current_query= \"\"\"Calculate the sum of exponentials of word \"TSAI\"\"\"\n",
    "iteration_1 = f\"In the first iteration you called {func_name} with {params} parameters, and the function returned {iteration_result}. What should I do next?\"\n",
    "\n",
    "prompt = f\"{system_prompt}\\n\\nQuery: {current_query}\\n\\n{iteration_1}\"\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=prompt\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_text = response.text.strip()\n",
    "_, function_info = response_text.split(\":\", 1)\n",
    "func_name, params = [x.strip() for x in function_info.split(\"|\", 1)]\n",
    "iteration_result = function_caller(func_name, params)\n",
    "iteration_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model's response\n",
    "system_prompt = \"\"\"You are a math agent solving problems in iterations. Respond with EXACTLY ONE of these formats:\n",
    "1. FUNCTION_CALL: python_function_name|input\n",
    "2. FINAL_ANSWER: [number]\n",
    "\n",
    "where python_function_name is one of the followin:\n",
    "1. strings_to_chars_to_int(string) It takes a word as input, and returns the ASCII INT values of characters in the word as a list\n",
    "2. int_list_to_exponential_sum(list) It takes a list of integers and returns the sum of exponentials of those integers\n",
    "3. fibonacci_numbers(int) It takes an integer, like 6, and returns first 6 integers in a fibonacci series as a list.\n",
    "DO NOT include multiple responses. Give ONE response at a time.\"\"\"\n",
    "\n",
    "current_query= \"\"\"Calculate the sum of exponentials of word \"TSAI\"\"\"\n",
    "iteration_1 = f\"In the first iteration you called strings_to_chars_to_int with TSAI parameters, and the function returned {iteration_result}. What should I do next?\"\n",
    "iteration_2 = f\"In the first iteration you called {func_name} with {params} parameters, and the function returned {iteration_result}. What should I do next?\"\n",
    "prompt = f\"{system_prompt}\\n\\nQuery: {current_query}\\n\\n{iteration_1}\\n\\n{iteration_2}\"\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=prompt\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iterations = 3\n",
    "last_response = None\n",
    "iteration = 0\n",
    "iteration_response = []\n",
    "\n",
    "system_prompt = \"\"\"You are a math agent solving problems in iterations. Respond with EXACTLY ONE of these formats:\n",
    "1. FUNCTION_CALL: python_function_name|input\n",
    "2. FINAL_ANSWER: [number]\n",
    "\n",
    "where python_function_name is one of the followin:\n",
    "1. strings_to_chars_to_int(string) It takes a word as input, and returns the ASCII INT values of characters in the word as a list\n",
    "2. int_list_to_exponential_sum(list) It takes a list of integers and returns the sum of exponentials of those integers\n",
    "3. fibonacci_numbers(int) It takes an integer, like 6, and returns first 6 integers in a fibonacci series as a list.\n",
    "DO NOT include multiple responses. Give ONE response at a time.\"\"\"\n",
    "\n",
    "query= \"\"\"Calculate the sum of exponentials of word \"TSAI\"\"\"\n",
    "\n",
    "while iteration < max_iterations:\n",
    "    print(f\"\\n--- Iteration {iteration + 1} ---\")\n",
    "    if last_response == None:\n",
    "        current_query = query\n",
    "    else:\n",
    "        current_query = current_query + \"\\n\\n\" + \" \".join(iteration_response)\n",
    "        current_query = current_query + \"  What should I do next?\"\n",
    "\n",
    "    # Get model's response\n",
    "    prompt = f\"{system_prompt}\\n\\nQuery: {current_query}\"\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        contents=prompt\n",
    "    )\n",
    "    \n",
    "    response_text = response.text.strip()\n",
    "    print(f\"LLM Response: {response_text}\")\n",
    "\n",
    "    \n",
    "    if response_text.startswith(\"FUNCTION_CALL:\"):\n",
    "        response_text = response.text.strip()\n",
    "        _, function_info = response_text.split(\":\", 1)\n",
    "        func_name, params = [x.strip() for x in function_info.split(\"|\", 1)]\n",
    "        iteration_result = function_caller(func_name, params)\n",
    "\n",
    "    # Check if it's the final answer\n",
    "    elif response_text.startswith(\"FINAL_ANSWER:\"):\n",
    "        print(\"\\n=== Agent Execution Complete ===\")\n",
    "        break\n",
    "        \n",
    "\n",
    "    print(f\"  Result: {iteration_result}\")\n",
    "    last_response = iteration_result\n",
    "    iteration_response.append(f\"In the {iteration + 1} iteration you called {func_name} with {params} parameters, and the function returned {iteration_result}.\")\n",
    "\n",
    "    iteration += 1\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
